{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import util\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from util import DataLoaderS\n",
    "from model import *\n",
    "from model_time_shift import A2GCN\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,#控制台打印的日志级别\n",
    "                    filename='logging_ablation.txt',\n",
    "                    filemode='a',##模式，有w和a，w就是写模式，每次都会重新写日志，覆盖之前的日志\n",
    "                    #a是追加模式，默认如果不写的话，就是追加模式\n",
    "                    format=\n",
    "                    '%(asctime)s : %(message)s',\n",
    "                    )\n",
    "\n",
    "logging.info('\\n\\n\\n*********************************start*************************\\n\\n\\n')\n",
    "device = torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = 8\n",
    "sparse = 1\n",
    "model = A2GCN(num_nodes, in_T = 12, in_dim = 1,out_T=1,out_dim=1,\n",
    "                predefined_G=None, \\\n",
    "                 channel =  32, sparse = int(num_nodes*sparse),gnn_layers=2,dropout=0.3,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = list(map(id,model.latent_graph.parameters()))\n",
    "other = filter(lambda x:id(x) not in base_params, model.parameters())\n",
    "optimizer = optim.Adam([\n",
    "            {'params':other, 'lr':1e-3, 'weight_decay':1e-4},\n",
    "            {'params':model.latent_graph.parameters(),'lr':1e-2},\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140470625887968]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正在跑去掉weight decay的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##solar 137\n",
    "##traffic 862\n",
    "##electricity 321\n",
    "###exchange-rate 8\n",
    "\n",
    "Data = DataLoaderS('./multivariate-time-series-data/exchange_rate/exchange_rate.txt', 0.6, 0.2, device, horizon=6,window=24*7,normalize = 2 )\n",
    "\n",
    "num_nodes = 8\n",
    "sparse = 1\n",
    "model = A2GCN(num_nodes, in_T = 12, in_dim = 1,out_T=1,out_dim=1,\n",
    "                ,predefined_G=supports, \\\n",
    "                 channel =  32, sparse = int(num_nodes*sparse),gnn_layers=layers,dropout=dropout,device=device,)\n",
    "\n",
    "\n",
    "t_shift_net(device, num_nodes=num_nodes, T=24*7,delta_T=24*7,dropout=0.3, supports=None, \\\n",
    "             in_dim=1, out_dim=1, residual_channels=16, \\\n",
    "             skip_channels=256, end_channels=512,layers = 1,sparse = sparse,)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "            {'params':filter(lambda x:id(x) not in [id(model.new_supports),], model.parameters()), 'lr':1e-3, 'weight_decay':1e-4},\n",
    "#             {'params':model.nodevec1,'lr':1e-2},\n",
    "#             {'params':model.nodevec2,'lr':1e-2},\n",
    "            {'params':model.new_supports,'lr':1e-2},\n",
    "                                    ])\n",
    "\n",
    "evaluateL2 = nn.MSELoss(size_average=False).to(device)\n",
    "evaluateL1 = nn.L1Loss(size_average=False).to(device)                                \n",
    "\n",
    "logging.info('\\n\\n\\n*********************************start*************************\\n\\n\\n')\n",
    "\n",
    "def evaluate(data, X, Y, model, evaluateL2, evaluateL1, batch_size):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_l1 = 0\n",
    "    n_samples = 0\n",
    "    predict = None\n",
    "    test = None\n",
    "\n",
    "    for X, Y in data.get_batches(X, Y, batch_size, False):\n",
    "        X = X.unsqueeze(dim = 1).permute(0,1,3,2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(X)\n",
    "        output = torch.squeeze(output)\n",
    "        if len(output.shape)==1:\n",
    "            output = output.unsqueeze(dim=0)\n",
    "        if predict is None:\n",
    "            predict = output\n",
    "            test = Y\n",
    "        else:\n",
    "            predict = torch.cat((predict, output))\n",
    "            test = torch.cat((test, Y))\n",
    "\n",
    "        scale = data.scale.expand(output.size(0), data.m)\n",
    "        total_loss += evaluateL2(output * scale, Y * scale).item()\n",
    "        total_loss_l1 += evaluateL1(output * scale, Y * scale).item()\n",
    "        n_samples += (output.size(0) * data.m)\n",
    "    \n",
    "\n",
    "    rse = math.sqrt(total_loss / n_samples) / data.rse\n",
    "    rae = (total_loss_l1 / n_samples) / data.rae\n",
    "\n",
    "    predict = predict.data.cpu().numpy()\n",
    "    Ytest = test.data.cpu().numpy()\n",
    "    sigma_p = (predict).std(axis=0)\n",
    "    sigma_g = (Ytest).std(axis=0)\n",
    "    mean_p = predict.mean(axis=0)\n",
    "    mean_g = Ytest.mean(axis=0)\n",
    "    index = (sigma_g != 0)\n",
    "    correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis=0) / (sigma_p * sigma_g)\n",
    "    correlation = (correlation[index]).mean()\n",
    "    return rse, rae, correlation\n",
    "\n",
    "for ep in range(60):\n",
    "    print('*******{}*******'.format(ep))\n",
    "    logging.info('*******{}*******'.format(ep))\n",
    "    \n",
    "    losses = []\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    for x,y in Data.get_batches(Data.train[0], Data.train[1],4,True):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.unsqueeze(dim = 1).permute(0,1,3,2)\n",
    "        out = model(x)\n",
    "        out = out.squeeze()\n",
    "        scale = Data.scale.unsqueeze(dim = 0)\n",
    "        loss = evaluateL1(out*scale,y*scale)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        if len(losses)%50 == 0:\n",
    "            print(np.mean(losses))\n",
    "    now = time.time()\n",
    "    print('train epoch time: {:.2f} \\s'.format(now- start))\n",
    "    logging.info('train epoch time: {:.2f} \\s'.format(now- start))\n",
    "    \n",
    "    r1 = evaluate(Data,Data.valid[0], Data.valid[1], model, evaluateL2, evaluateL1,64)\n",
    "    r2 = evaluate(Data,Data.test[0], Data.test[1], model, evaluateL2, evaluateL1,64)\n",
    "\n",
    "    print('inference time: {:.2f} \\s'.format(0.5*(time.time()- now)))\n",
    "\n",
    "    logging.info(' '.join([str(i) for i in r1+r2]))\n",
    "    print(r1,r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
